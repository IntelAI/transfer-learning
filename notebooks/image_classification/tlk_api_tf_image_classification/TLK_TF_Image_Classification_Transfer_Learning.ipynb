{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc0d761",
   "metadata": {},
   "source": [
    "# Transfer Learning for Image Classification using the TLK API\n",
    "\n",
    "This notebook uses the `tlk` library to do transfer learning for image classfication with a TensorFlow pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266ca11",
   "metadata": {},
   "source": [
    "## 1. Import dependencies and setup parameters\n",
    "\n",
    "This notebook assumes that you have already followed the instructions in the [notebooks README.md](/notebooks/README.md) to setup a TensorFlow environment with all the dependencies required to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from tlk.datasets import dataset_factory\n",
    "from tlk.models import model_factory\n",
    "\n",
    "# Specify a directory for the dataset to be downloaded\n",
    "dataset_dir = os.environ[\"DATASET_DIR\"] if \"DATASET_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"dataset\")\n",
    "     \n",
    "# Specify a directory for output\n",
    "output_dir = os.environ[\"OUTPUT_DIR\"] if \"OUTPUT_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"output\")\n",
    "\n",
    "print(\"Dataset directory:\", dataset_dir)\n",
    "print(\"Output directory:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dafe3",
   "metadata": {},
   "source": [
    "## 2. Get the model\n",
    "\n",
    "In this step, we call the TLK model factory to list supported TensorFlow image classification models. This is a list of pretrained models from [TFHub](https://tfhub.dev) that we tested with our API. Optionally, the `verbose=True` argument can be added to the `print_supported_models` function call to get more information about each model (such as the link to TFHub, image size, the original dataset, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a list of available models\n",
    "model_factory.print_supported_models(use_case='image_classification', framework='tensorflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c7063",
   "metadata": {},
   "source": [
    "Next, use the TLK model factory to get one of the models listed in the previous cell. The `get_model` function returns a TLK model object that will later be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_factory.get_model(model_name='efficientnet_b0', framework='tensorflow')\n",
    "\n",
    "print(\"Model name:\", model.model_name)\n",
    "print(\"Framework:\", model.framework)\n",
    "print(\"Use case:\", model.use_case)\n",
    "print(\"Image size:\", model.image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351fbbc",
   "metadata": {},
   "source": [
    "## 3. Prepare the dataset\n",
    "\n",
    "We call the TLK dataset factory to get a sample image classification dataset. For demonstration purposes, we are using the [tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers) dataset from the [TensorFlow Datasets catalog](https://www.tensorflow.org/datasets). This dataset contains images of flowers in 5 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers = dataset_factory.get_dataset(dataset_dir=dataset_dir,\n",
    "                                      use_case='image_classification', \n",
    "                                      framework='tensorflow',\n",
    "                                      dataset_name='tf_flowers',\n",
    "                                      dataset_catalog='tf_datasets')\n",
    "\n",
    "print(flowers.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03321b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class names:\", str(flowers.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c883c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset with an image size that matches the model and a batch size of 32\n",
    "flowers.preprocess(model.image_size, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7208e757",
   "metadata": {},
   "source": [
    "## 4. Transfer Learning\n",
    "\n",
    "This step calls the TLK model's train function with the dataset that was just prepared. The training function will get the TFHub feature vector and add on a dense layer based on the number of classes in the dataset. The model is then compiled and trained based on the number of epochs specified in the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d51156",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.train(flowers, output_dir=output_dir, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f75fa0",
   "metadata": {},
   "source": [
    "## 5. Evaluate\n",
    "\n",
    "The next step shows how the model can be evaluated. Pass a dataset to the model's evaluate function, and it returns a a list of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104099d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation metrics\n",
    "for metric_name, metric_value in zip(model._model.metrics_names, metrics):\n",
    "    print(\"{}: {}\".format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deba432",
   "metadata": {},
   "source": [
    "## 6. Predict\n",
    "\n",
    "To predict with a single batch, we first call `get_batch` from our TLK dataset object to get a list of images and labels for a single batch. We map the labels to our class names to get the human readable string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = flowers.get_batch()\n",
    "labels = [flowers.class_names[id] for id in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066de99",
   "metadata": {},
   "source": [
    "Next, call the `predict` function from our TLK model object with our batch of images to get a list of predictions. Again, we map these predictions to our dataset's class names to get the human readable string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2aa7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(images)\n",
    "predictions = [flowers.class_names[id] for id in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f63692",
   "metadata": {},
   "source": [
    "We create a dataset frame to display the predicted labels with the actual label for our batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a results table to list out the class prediction vs the actual dataset label\n",
    "results_table = []\n",
    "for prediction, actual in zip(predictions, labels):\n",
    "    results_table.append([prediction, actual])\n",
    "\n",
    "pd.DataFrame(results_table, columns=[\"Prediction\", \"Actual Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e89712",
   "metadata": {},
   "source": [
    "We can also visualize results by displaying the image along with it's predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7252ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the images with the predict label\n",
    "plt.figure(figsize=(18,14))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(images[n])\n",
    "    plt.title(predictions[n].title(), fontsize=16)\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b765cf",
   "metadata": {},
   "source": [
    "We can also predict using a single image that wasn't part of our original dataset. We download a flower image from the [Open Images Dataset](https://storage.googleapis.com/openimages/web/index.html) and then resize it to match our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an image from the web and resize it to match our model\n",
    "image_url = 'https://c8.staticflickr.com/8/7095/7210797228_c7fe51c3cb_z.jpg'\n",
    "daisy = tf.keras.utils.get_file(origin=image_url)\n",
    "\n",
    "image_shape = (model.image_size, model.image_size)\n",
    "daisy = Image.open(daisy).resize(image_shape)\n",
    "daisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e31a87",
   "metadata": {},
   "source": [
    "Then, we call predict by passing the np array for our image and add a dimension to our array to represent the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image as a np array and call predict while adding a batch dimension (with np.newaxis) \n",
    "daisy = np.array(daisy)/255.0\n",
    "result = model.predict(daisy[np.newaxis, ...])\n",
    "\n",
    "# Print the predicted class name\n",
    "print(flowers.class_names[result[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007cc8fe",
   "metadata": {},
   "source": [
    "## 7. Export\n",
    "\n",
    "Lastly, we can call the TLK model `export` function to generate a `saved_model.pb`. The model is saved in a format that is ready to use with [TensorFlow Serving](https://github.com/tensorflow/serving). Each time the model is exported, a new numbered directory is created, which allows serving to pick up the latest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed84d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fb6ff",
   "metadata": {},
   "source": [
    "## Dataset Citations\n",
    "\n",
    "```\n",
    "@ONLINE {tfflowers,\n",
    "author = \"The TensorFlow Team\",\n",
    "title = \"Flowers\",\n",
    "month = \"jan\",\n",
    "year = \"2019\",\n",
    "url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\n",
    "\n",
    "@article{openimages,\n",
    "  title={OpenImages: A public dataset for large-scale multi-label and multi-class image classification.},\n",
    "  author={Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Veit, Andreas and Abu-El-Haija, Sami\n",
    "    and Belongie, Serge and Cai, David and Feng, Zheyun and Ferrari, Vittorio and Gomes, Victor\n",
    "    and Gupta, Abhinav and Narayanan, Dhyanesh and Sun, Chen and Chechik, Gal and Murphy, Kevin},\n",
    "  journal={Dataset available from https://github.com/openimages},\n",
    "  year={2016}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
