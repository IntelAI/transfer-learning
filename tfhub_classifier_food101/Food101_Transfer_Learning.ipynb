{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Food-101 Image Classification\n",
    "\n",
    "This notebook uses a classifier model that was originally trained using [ImageNet](https://image-net.org) and does transfer learning with the [Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/). The Food-101 dataset has 101,000 images of food in 101 categories.\n",
    "\n",
    "The notebook performs the following steps:\n",
    "1. [Install dependencies and setup parameters](#1.-Install-dependencies-and-setup-parameters)\n",
    "2. [Prepare the dataset](#2.-Prepare-the-dataset)\n",
    "3. [Predict using the original model](#3.-Predict-using-the-original-model)\n",
    "4. [Transfer learning](#4.-Transfer-Learning)\n",
    "5. [Evaluate the model](#5.-Evaluate-the-model)\n",
    "6. [Export the saved model](#6.-Export-the-saved-model)\n",
    "\n",
    "Dataset citation:\n",
    "```\n",
    "@inproceedings{bossard14,\n",
    "  title = {Food-101 -- Mining Discriminative Components with Random Forests},\n",
    "  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},\n",
    "  booktitle = {European Conference on Computer Vision},\n",
    "  year = {2014}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies and setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets==7.6.5 \\\n",
    "             tensorflow_hub==0.12.0 \\\n",
    "             tensorflow-datasets==4.4.0 \\\n",
    "             'pandas>=1.1.5' \\\n",
    "             'matplotlib>=3.3.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify a model from the tfhub_model_map dictionary\n",
    "model_name = \"efficientnet_b0\"\n",
    "\n",
    "# Specify the location for the dataset to be downloaded\n",
    "dataset_directory = os.environ[\"DATASET_DIR\"] if \"DATASET_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"food101_dataset\")\n",
    "    \n",
    "# Specify a directory for output\n",
    "output_directory = os.environ[\"OUTPUT_DIR\"] if \"OUTPUT_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"food101_output\")\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Number of training epochs\n",
    "training_epochs = 1\n",
    "\n",
    "# To reduce training time, the feature extractor layer can remain frozen (do_fine_tuning=False).\n",
    "# Fine-tuning can be enabled to potentially get better accuracy. Note that enabling fine-tuning\n",
    "# will increase training time.\n",
    "do_fine_tuning = False\n",
    "\n",
    "# Optionally add a dropout layer (set to a float between 0 and 1, or None).\n",
    "# If set to None, no dropout layer will be added.\n",
    "dropout_layer_rate = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of TFHub models\n",
    "tfhub_model_map = {\n",
    "    \"resnet_v1_50\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/classification/5\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature_vector/5\",\n",
    "        \"image_size\": 224\n",
    "    },\n",
    "    \"resnet_v2_50\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\",\n",
    "        \"image_size\": 224\n",
    "    },\n",
    "    \"resnet_v2_101\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/5\",\n",
    "        \"image_size\": 224\n",
    "    },\n",
    "    \"mobilenet_v2_100_224\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "        \"image_size\": 224\n",
    "    },\n",
    "    \"efficientnetv2-s\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/classification/2\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\",\n",
    "        \"image_size\": 384\n",
    "    },\n",
    "    \"efficientnet_b0\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/efficientnet/b0/classification/1\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\",\n",
    "        \"image_size\": 224\n",
    "    },\n",
    "    \"efficientnet_b1\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/efficientnet/b1/classification/1\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/efficientnet/b1/feature-vector/1\",\n",
    "        \"image_size\": 240\n",
    "    },\n",
    "    \"efficientnet_b2\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/efficientnet/b2/classification/1\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/efficientnet/b2/feature-vector/1\",\n",
    "        \"image_size\": 260\n",
    "    },\n",
    "    \"inception_v3\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5\",\n",
    "        \"image_size\": 299\n",
    "    },\n",
    "    \"nasnet_large\": {\n",
    "        \"imagenet_model\": \"https://tfhub.dev/google/imagenet/nasnet_large/classification/5\",\n",
    "        \"feature_vector\": \"https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/5\",\n",
    "        \"image_size\": 331\n",
    "    }\n",
    "}\n",
    "\n",
    "if model_name not in tfhub_model_map.keys():\n",
    "    raise ValueError(\"The specified model_name ({}) is invalid. Please select from: {}\".\n",
    "                     format(model_name, tfhub_model_map.keys()))\n",
    "    \n",
    "# Get the info for the specified model from the map\n",
    "model_map_values = tfhub_model_map[model_name]\n",
    "model_handle = tfhub_model_map[model_name][\"imagenet_model\"]\n",
    "feature_vector_handle = tfhub_model_map[model_name][\"feature_vector\"]\n",
    "image_size = tfhub_model_map[model_name][\"image_size\"]\n",
    "print(\"Model:\", model_name)\n",
    "print(\"Classifier model:\", model_handle)\n",
    "print(\"Feature vector:\", feature_vector_handle)\n",
    "print(\"Image size:\", image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the dataset\n",
    "\n",
    "Load the [Food-101 dataset using the TensorFlow datasets API](https://www.tensorflow.org/datasets/catalog/food101), and then preprocess the images to convert them to float32 and resize the images. The data is split into a `train` and `test` set to use for training and validation. If the dataset is not found in the dataset directory it is downloaded. Subsequent runs will reuse the already downloaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 'food101' dataset using the TensorFlow datasets API\n",
    "[train_ds, test_ds], info = tfds.load(\"food101\",\n",
    "                           data_dir=dataset_directory,\n",
    "                           split=[\"train\", \"validation\"],\n",
    "                           as_supervised=True,\n",
    "                           shuffle_files=True,\n",
    "                           with_info=True)\n",
    "\n",
    "# Preprocess the images to convert them to float32 and resize the images to match our model\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize_with_pad(image, image_size, image_size)\n",
    "    return (image, label)\n",
    "\n",
    "train_ds = train_ds.map(preprocess_image)\n",
    "test_ds = test_ds.map(preprocess_image)\n",
    "\n",
    "print(\"Dataset directory: \", dataset_directory)\n",
    "print(\"Training dataset size:\", len(train_ds))\n",
    "print(\"Validation dataset size:\", len(test_ds))\n",
    "\n",
    "# Training data is shuffled for randomness\n",
    "# https://www.tensorflow.org/datasets/keras_example#build_a_training_pipeline\n",
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.shuffle(info.splits['train'].num_examples)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Test data does not need to be shuffled, and caching is done after batching\n",
    "# https://www.tensorflow.org/datasets/keras_example#build_an_evaluation_pipeline\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "test_ds = test_ds.cache()\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Get class names for the dataset\n",
    "class_names = info.features[\"label\"].names\n",
    "print(\"Number of classes:\", len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict using the original model\n",
    "\n",
    "Use the classifier model that was trained using ImageNet to do predictions with the food dataset and view the results for a single batch. Table below compares the prediction made by the ImageNet trained model with the actual label from the Food-101 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of the dataset to use for testing\n",
    "batch = next(iter(test_ds))\n",
    "image_batch, label_batch = batch\n",
    "\n",
    "# List of the actual labels for this batch\n",
    "actual_label_batch = [class_names[id] for id in label_batch]\n",
    "\n",
    "# Download the ImageNet labels and load them into a list\n",
    "labels_file = \"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\"\n",
    "downloaded_file = tf.keras.utils.get_file(\"labels.txt\", origin=labels_file)\n",
    "imagenet_classes = []\n",
    "\n",
    "with open(downloaded_file) as f:\n",
    "    imagenet_labels = f.readlines()\n",
    "    imagenet_classes = [l.strip() for l in imagenet_labels]\n",
    "\n",
    "# Predict using the TF Hub classifier that was trained using ImageNet\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(model_handle, input_shape=(image_size, image_size)+(3,))\n",
    "])\n",
    "predicted_batch = classifier.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = [imagenet_classes[id] for id in predicted_id]\n",
    "\n",
    "# Create a results table to list out the ImageNet class prediction vs the actual Food-101 dataset label\n",
    "results_table = []\n",
    "for prediction, actual in zip(predicted_label_batch, actual_label_batch):\n",
    "    results_table.append([prediction, actual])\n",
    "\n",
    "pd.DataFrame(results_table, columns=[\"ImageNet Prediction\", \"Actual Food-101 label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    plt.title(predicted_label_batch[n].title(), fontsize=9)\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"ImageNet predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transfer Learning\n",
    "\n",
    "Get the feature vector from TF Hub and add on a dense layer based on the number of classes in our dataset. Train the model using the Food-101 training dataset for the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(feature_vector_handle,\n",
    "                                         input_shape=(image_size, image_size, 3),\n",
    "                                         trainable=do_fine_tuning)\n",
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "\n",
    "if dropout_layer_rate == None:\n",
    "    model = tf.keras.Sequential([\n",
    "      feature_extractor_layer,\n",
    "      tf.keras.layers.Dense(len(class_names))\n",
    "    ])\n",
    "else:\n",
    "    model = tf.keras.Sequential([\n",
    "      feature_extractor_layer,\n",
    "      tf.keras.layers.Dropout(dropout_layer_rate),\n",
    "      tf.keras.layers.Dense(len(class_names))\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    self.model.reset_metrics()\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "history = model.fit(train_ds, epochs=training_epochs, shuffle=True, callbacks=[batch_stats_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model\n",
    "\n",
    "After the training completes, evaluate the model's accuracy using the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.evaluate(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, predict using the same sample batch that we used earlier with the ImageNet trained classier to visualize the results after training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the sample batch\n",
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = [class_names[id] for id in predicted_id]\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    correct_prediction = actual_label_batch[n] == predicted_label_batch[n]\n",
    "    color = \"darkgreen\" if correct_prediction else \"crimson\"\n",
    "    title = predicted_label_batch[n].title() if correct_prediction else \"{}\\n({})\".format(predicted_label_batch[n], actual_label_batch[n]) \n",
    "    plt.title(title, fontsize=9, color=color)\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")\n",
    "plt.show()\n",
    "print(\"Correct predictions are shown in green\")\n",
    "print(\"Incorrect predictions are shown in red with the actual Food-101 label in parenthesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = os.path.join(output_directory, \"{}_saved_model\".format(model_name))\n",
    "model.save(saved_model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
